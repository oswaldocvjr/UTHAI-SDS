{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folktables Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook uses the folktable data found [here](https://github.com/zykls/folktables). <br>\n",
    "Full 2018 ACS documentation found [here](https://www2.census.gov/programs-surveys/acs/tech_docs/pums/data_dict/PUMS_Data_Dictionary_2018.txt). <br>\n",
    "Intro to ACS public use: [video link](https://www.census.gov/data/academy/webinars/2020/introduction-to-american-community-survey-public-use-microdata-sample-pums-files.html).\n",
    "\n",
    "### Definitions:\n",
    "\n",
    "**ACS (American Community Survey)** - Information from the survey generates data that help determine how more than $675 billion in federal and state funds are distributed each year. Unlike the every-10-year census, this survey continues all year, every year. ACS randomly samples addresses in every state, the District of Columbia, and Puerto Rico. \n",
    "\n",
    "**ACSEmployment data**\n",
    "\n",
    "<code> features </code> **- the independent variables**\n",
    "* ['AGEP', 'SCHL', 'MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC', 'NATIVITY', 'DEAR', 'DEYE', 'DREM', 'SEX', 'RAC1P']\n",
    "| Feature      | Description                   |\n",
    "| :---         | :---                          |\n",
    "| AGEP         | Age                           |\n",
    "| SCHL         | Educational attainment        |\n",
    "| Mar          | Marital status                |\n",
    "| RELP         | Relationship                  |\n",
    "| DIS          | Disability recode             |\n",
    "| ESP          | Employment status of parents  |\n",
    "| CIT          | Citizenship status            |\n",
    "| MIG          | Mobility status (lived here 1 year ago)|\n",
    "| MIL          | Military service              |\n",
    "| ANC          | Ancestry recode               |\n",
    "| NATIVITY     | Native or Foreign born        |\n",
    "| DEAR         | Hearing difficulty            |\n",
    "| DEYE         | Vision difficulty             |\n",
    "| DREM         | Cognitive difficulty          |\n",
    "| SEX          | Male or Female                |\n",
    "| RAC1P        | Recoded detailed race code    |\n",
    "\n",
    "\n",
    "       \n",
    "<code> group </code> **- race group**\n",
    "* 1    .White alone\n",
    "* 2    .Black or African American alone\n",
    "* 3    .American Indian alone\n",
    "* 4    .Alaska Native alone\n",
    "* 5    .American Indian and Alaska Native tribes specified; or American   Indian or Alaska Native, not specified and no other races\n",
    "* 6    .Asian alone\n",
    "* 7    .Native Hawaiian and Other Pacific Islander alone\n",
    "* 8    .Some Other Race alone\n",
    "* 9    .Two or More Races\n",
    "\n",
    "<code>nav_group </code> **- native group**\n",
    "* 1    .Native\n",
    "* 2    .Foreign born\n",
    "\n",
    "<code>sex_group </code> **- sex group**\n",
    "* 1    .Male\n",
    "* 2    .Female\n",
    "\n",
    "<code> labels </code> **- Employment status recode**\n",
    "* b    .N/A (less than 16 years old)\n",
    "* 1    .Civilian employed, at work\n",
    "* 2    .Civilian employed, with a job but not at work\n",
    "* 3    .Unemployed\n",
    "* 4    .Armed forces, at work\n",
    "* 5    .Armed forces, with a job but not at work\n",
    "* 6    .Not in labor force\n",
    "\n",
    "<code>cont_labels </code> **- Wages & income**\n",
    "* **NOTE:** There are some NaN values present in this 2018 CA dataset.\n",
    "\n",
    "---\n",
    "**NOTE:** This a personal documentation of what I have learned from fairlearn since 9/11/2022.\n",
    "### fairlearn packages:\n",
    "\n",
    "**datasets** - fetch sample datasets \n",
    "\n",
    "**metrics** - functionality for computing metrics with a focus on ‘disaggregated metrics’. This is a metric where in addition to y_true and y_pred values, the user provides information about group membership for each sample. \n",
    "\n",
    "**postprocessing** - methods which operate on the predictor (i.e. X) rather than the estimator (i.e. Y). \n",
    "\n",
    "**preprocessing**  - a filtering technique that eliminates sensitive correlations in the dataset. \n",
    "\n",
    "**reductions** - This module contains algorithms implementing the reductions approach to disparity mitigation. In this approach, disparity constraints are cast as Lagrange multipliers, which cause the reweighting and relabelling of the input data. This reduces the problem back to standard machine learning training.\n",
    "\n",
    "### fairlearn can and can’t:\n",
    "**can -**\n",
    "* **Fairness Assessments** [link](https://fairlearn.org/main/user_guide/assessment.html)\n",
    "* **Demographic Parity** - a fairness metric whose goal is to ensure a machine learning model’s predictions are independent of membership in a sensitive group. $$E[h(X)|A=a]=E[h(X)], \\forall a$$\n",
    "$$P[f(X) \\leq z|A=a]=P[f(X)\\leq z],  \\forall a, z$$ where $A$ is a sensitive feature, $h$ is a classifier, and $f$ is a regressor.<br>\n",
    "<code>demographic_parity_difference()</code>  - Returns the absolute difference between the highest and lowest selection rates of the sensitive groups. A result of 0 means there is a demographic parity. (only for classifiers). <br>\n",
    "<code>demographic_parity_ratio()</code> - Returns the ratio of the lowest and highest selection rates. A result of 1 means there is a demographic parity.\n",
    "* **Equalized Odds** - The goal of the equalized odds fairness metric is to ensure a machine learning model performs equally well for different groups. It is stricter than demographic parity because it requires that the machine learning model’s predictions are not only independent of sensitive group membership, but that groups have the same false positive rates and true positive rates. $$E[h(X)|A=a, Y=y]=E[h(X)|Y=y],  \\forall a, y$$ AND \n",
    "that the true positive rate and false positive rate be equal across groups (classifiers). <br>\n",
    "<code>equalized_odds_difference()</code> - Returns the largest difference between the TRP difference and FPR difference. <br>\n",
    "<code>equalized_odds_ratio()</code> - Returns the the smallest ratio between the TRP ratio and FPR ratio. \n",
    "* **Equal Opportunity** - Equal opportunity is a relaxed version of equalized odds that only considers conditional expectations with respect to positive labels. NOTE: The developers of fairlearn suggest that this fairness metric can overlook misclassifications since it does not consider false positive rates.\n",
    "* **Intersecting Groups** - Fairlearn supports metric assessment in the scenario of intersection of multiple sensitive features. <br>\n",
    "<code>MetricFrame.by_group</code> - Returns a table that displays all the possible combinations of sensitive groups and their fairness metric results.\n",
    "* **Control Feature**\n",
    "* **Group by Group Visualizations**\n",
    "* **Unfairness Mitigations** - algorithm related techniques to mitigate unfairness. Full list of algorithms and their basic descriptions found here.\n",
    "---\n",
    "* **Fairness Mitigation** [link](https://fairlearn.org/main/user_guide/mitigation.html)\n",
    "* <code>ExponentiatedGradient</code>\n",
    "* <code>GridSearch</code>\n",
    "* <code>ThresholdOptimizer</code>\n",
    "* <code>CorrelationRemover</code>\n",
    "\n",
    "**can’t -** \n",
    "* Fairly limited in number of postprocessing and preprocessing techniques. Most of the assessment tools that fairlearn offers inherit from the ‘metrics’ package.\n",
    "* I have yet to find a focus on unsupervised related techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from folktables import ACSDataSource, ACSEmployment\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from fairlearn.metrics import MetricFrame\n",
    "from fairlearn.metrics import count, \\\n",
    "                              false_positive_rate, \\\n",
    "                              selection_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**The following exercise deals with trying different fairness metrics, and mitigation techniques with classifers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "features, label, group = ACSEmployment.df_to_numpy(acs_data)\n",
    "\n",
    "# create sensitive feature(s):\n",
    "nat_group = acs_data[\"NATIVITY\"]\n",
    "sex_group = acs_data[\"SEX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying encodings\n",
    "race = {\n",
    "    1: \"White alone\",\n",
    "    2: \"Black or African American alone\",\n",
    "    3: \"American Indian alone\",\n",
    "    4: \"American Indian alone\",\n",
    "    5: \"American Indian/Alaska Native specified/not specified or no other races\", # truncated for index purposes\n",
    "    6: \"Asian alone\",\n",
    "    7: \"Native Hawaiian and Other Pacific Islander alone\",\n",
    "    8: \"Some Other Race alone\",\n",
    "    9: \"Two or More Races\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a standard scaler for the data\n",
    "scaler = StandardScaler().fit(features)\n",
    "#scaler_cont = StandardScaler().fit(np.array(cont_labels).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model Accuracy is: 0.7728736603136054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04549392964278809"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, cont_train, cont_test, group_train, group_test, sex_train, sex_test, nat_train, nat_test = train_test_split(\n",
    "    features, label, cont_labels, group, sex_group, nat_group, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "###### Your favorite LINEAR learning algorithm here #####\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print(\"Linear Model Accuracy is:\", accuracy)\n",
    "\n",
    "white_tpr = np.mean(yhat[(y_test == 1) & (group_test == 1)])\n",
    "black_tpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "# Equality of opportunity violation: 0.0455\n",
    "white_tpr - black_tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---fairlearn library: linear---\n",
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a function dictionary\n",
    "my_metrics = {\n",
    "    'accuracy' : accuracy_score,\n",
    "    'tpr' : recall_score,\n",
    "    'fpr' : false_positive_rate,\n",
    "    'sel' : selection_rate,\n",
    "    'count' : count\n",
    "}\n",
    "# Construct a MetricFrame\n",
    "mf = MetricFrame(\n",
    "    metrics=my_metrics,\n",
    "    y_true=y_test,\n",
    "    y_pred=yhat,\n",
    "    sensitive_features={\"Race\":group_test}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy    0.772874\n",
       "tpr         0.833304\n",
       "fpr         0.277458\n",
       "sel         0.530041\n",
       "count          75764\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall True Positive Rate, False Positive Rate, Selection Rate, Counts\n",
    "mf.overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>sel</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>White alone</th>\n",
       "      <td>0.774938</td>\n",
       "      <td>0.825167</td>\n",
       "      <td>0.266918</td>\n",
       "      <td>0.520662</td>\n",
       "      <td>46245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black or African American alone</th>\n",
       "      <td>0.769168</td>\n",
       "      <td>0.779673</td>\n",
       "      <td>0.237753</td>\n",
       "      <td>0.452994</td>\n",
       "      <td>3691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Indian alone</th>\n",
       "      <td>0.76225</td>\n",
       "      <td>0.798077</td>\n",
       "      <td>0.259475</td>\n",
       "      <td>0.462795</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Indian alone</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Indian/Alaska Native specified/not specified or no other races</th>\n",
       "      <td>0.69375</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian alone</th>\n",
       "      <td>0.757683</td>\n",
       "      <td>0.887422</td>\n",
       "      <td>0.37091</td>\n",
       "      <td>0.62802</td>\n",
       "      <td>12170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Native Hawaiian and Other Pacific Islander alone</th>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.351145</td>\n",
       "      <td>0.538793</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Some Other Race alone</th>\n",
       "      <td>0.765173</td>\n",
       "      <td>0.810706</td>\n",
       "      <td>0.273517</td>\n",
       "      <td>0.520286</td>\n",
       "      <td>8947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two or More Races</th>\n",
       "      <td>0.827843</td>\n",
       "      <td>0.863439</td>\n",
       "      <td>0.192857</td>\n",
       "      <td>0.439426</td>\n",
       "      <td>3764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    accuracy       tpr  \\\n",
       "Race                                                                     \n",
       "White alone                                         0.774938  0.825167   \n",
       "Black or African American alone                     0.769168  0.779673   \n",
       "American Indian alone                                0.76225  0.798077   \n",
       "American Indian alone                                    0.5       0.5   \n",
       "American Indian/Alaska Native specified/not spe...   0.69375  0.658228   \n",
       "Asian alone                                         0.757683  0.887422   \n",
       "Native Hawaiian and Other Pacific Islander alone    0.706897  0.782178   \n",
       "Some Other Race alone                               0.765173  0.810706   \n",
       "Two or More Races                                   0.827843  0.863439   \n",
       "\n",
       "                                                         fpr       sel  count  \n",
       "Race                                                                           \n",
       "White alone                                         0.266918  0.520662  46245  \n",
       "Black or African American alone                     0.237753  0.452994   3691  \n",
       "American Indian alone                               0.259475  0.462795    551  \n",
       "American Indian alone                                    0.5       0.5      4  \n",
       "American Indian/Alaska Native specified/not spe...  0.271605    0.4625    160  \n",
       "Asian alone                                          0.37091   0.62802  12170  \n",
       "Native Hawaiian and Other Pacific Islander alone    0.351145  0.538793    232  \n",
       "Some Other Race alone                               0.273517  0.520286   8947  \n",
       "Two or More Races                                   0.192857  0.439426   3764  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by group analysis\n",
    "linear_results = mf.by_group.rename(index=race)\n",
    "linear_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographic Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import demographic_parity_difference\n",
    "from fairlearn.metrics import demographic_parity_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Demographic Parity Difference is: 0.1885935782227861\n"
     ]
    }
   ],
   "source": [
    "diff_dem = demographic_parity_difference(y_test, yhat, sensitive_features=group_test)\n",
    "print(\"The Demographic Parity Difference is:\", diff_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Demographic Parity Ratio is: 0.6997011844862872\n"
     ]
    }
   ],
   "source": [
    "ratio_dem = demographic_parity_ratio(y_test, yhat, sensitive_features=group_test)\n",
    "print(\"The Demographic Parity Ratio is:\", ratio_dem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result(s):**\n",
    "* A **demographic parity difference (DPD)** of 0 is what constitutes the presence of a demographic parity. For the race DPD, a result of 0.18859 means that a perfect demographic parity has not been achieved. If we take a look at the by group analysis we can see which race selection rates were used to calculate the DPD - asian alone and 2+ more races.\n",
    "* A **demographic parity ratio (DPR)** of 1 is what constitutes the presence of a demographic parity. For the race DPR, a result of 0.6997 means that a perfect demographic parity has not been achieved. If we take a look at the by group analysis we can see which race selection rates were used to calculate the DPR - asian alone and 2+ more races."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equalized Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import equalized_odds_difference\n",
    "from fairlearn.metrics import equalized_odds_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Equalized Odds Difference is: 0.38742159128425224\n"
     ]
    }
   ],
   "source": [
    "diff_EO = equalized_odds_difference(y_test, yhat, sensitive_features=group_test)\n",
    "print(\"The Equalized Odds Difference is:\", diff_EO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Equalized Odds Ratio is: 0.38571428571428573\n"
     ]
    }
   ],
   "source": [
    "ratio_EO = equalized_odds_ratio(y_test, yhat, sensitive_features=group_test)\n",
    "print(\"The Equalized Odds Ratio is:\", ratio_EO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result(s):**\n",
    "* A **equalized odds difference (EOD)** of 0 is what constitutes the presence of equalized odds. For the race EOD, a result of 0.3874 means that perfect equalized odds have not been achieved. If we take a look at the by group analysis we can see which race selection rates were used to calculate the EOD - alaska native and asian alone. NOTE: The alaska native alone group only contains 4 entries.\n",
    "* A **equalized odds ratio (EOR)** of 1 is what constitutes the presence of equalized odds. For the race EOR, a result of 0.3857 means that perfect equalized odds have not been achieved. If we take a look at the by group analysis we can see which race selection rates were used to calculate the EOR - alaska native and asian alone. NOTE: The alaska native alone group only contains 4 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersecting Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_f_frame = {\n",
    "    \"Race\": group_test,\n",
    "    \"Sex\": sex_test\n",
    "}\n",
    "\n",
    "metric_2sf = MetricFrame(metrics=my_metrics,\n",
    "                         y_true=y_test,\n",
    "                         y_pred=yhat,\n",
    "                         sensitive_features=s_f_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>sel</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.789591</td>\n",
       "      <td>0.863236</td>\n",
       "      <td>0.282498</td>\n",
       "      <td>0.569766</td>\n",
       "      <td>22941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.760513</td>\n",
       "      <td>0.7805</td>\n",
       "      <td>0.253668</td>\n",
       "      <td>0.472322</td>\n",
       "      <td>23304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.764063</td>\n",
       "      <td>0.843615</td>\n",
       "      <td>0.284832</td>\n",
       "      <td>0.497542</td>\n",
       "      <td>1831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.721717</td>\n",
       "      <td>0.188818</td>\n",
       "      <td>0.40914</td>\n",
       "      <td>1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>1</th>\n",
       "      <td>0.798535</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.498168</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.726619</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>0.260116</td>\n",
       "      <td>0.428058</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>1</th>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.64557</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.35443</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>1</th>\n",
       "      <td>0.78045</td>\n",
       "      <td>0.930757</td>\n",
       "      <td>0.391384</td>\n",
       "      <td>0.679093</td>\n",
       "      <td>5821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.736809</td>\n",
       "      <td>0.841856</td>\n",
       "      <td>0.354535</td>\n",
       "      <td>0.581194</td>\n",
       "      <td>6349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>1</th>\n",
       "      <td>0.713043</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.700855</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.470085</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>1</th>\n",
       "      <td>0.809064</td>\n",
       "      <td>0.857268</td>\n",
       "      <td>0.241921</td>\n",
       "      <td>0.558223</td>\n",
       "      <td>4457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.721604</td>\n",
       "      <td>0.752062</td>\n",
       "      <td>0.299139</td>\n",
       "      <td>0.482628</td>\n",
       "      <td>4490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">9</th>\n",
       "      <th>1</th>\n",
       "      <td>0.838969</td>\n",
       "      <td>0.907381</td>\n",
       "      <td>0.201365</td>\n",
       "      <td>0.463231</td>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.816938</td>\n",
       "      <td>0.819625</td>\n",
       "      <td>0.184603</td>\n",
       "      <td>0.416097</td>\n",
       "      <td>1901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy       tpr       fpr       sel  count\n",
       "Race Sex                                               \n",
       "1    1    0.789591  0.863236  0.282498  0.569766  22941\n",
       "     2    0.760513    0.7805  0.253668  0.472322  23304\n",
       "2    1    0.764063  0.843615  0.284832  0.497542   1831\n",
       "     2    0.774194  0.721717  0.188818   0.40914   1860\n",
       "3    1    0.798535  0.893204  0.258824  0.498168    273\n",
       "     2    0.726619  0.704762  0.260116  0.428058    278\n",
       "4    1           1         1         0         1      1\n",
       "     2    0.333333         0       0.5  0.333333      3\n",
       "5    1    0.740741  0.790698  0.315789  0.567901     81\n",
       "     2     0.64557       0.5  0.232558   0.35443     79\n",
       "6    1     0.78045  0.930757  0.391384  0.679093   5821\n",
       "     2    0.736809  0.841856  0.354535  0.581194   6349\n",
       "7    1    0.713043  0.849057  0.403226  0.608696    115\n",
       "     2    0.700855  0.708333  0.304348  0.470085    117\n",
       "8    1    0.809064  0.857268  0.241921  0.558223   4457\n",
       "     2    0.721604  0.752062  0.299139  0.482628   4490\n",
       "9    1    0.838969  0.907381  0.201365  0.463231   1863\n",
       "     2    0.816938  0.819625  0.184603  0.416097   1901"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_2sf.by_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reductions: ThresholdOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.postprocessing import ThresholdOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sensitive features in terms of train-test sets\n",
    "sf_train = pd.DataFrame(data={\n",
    "    \"group_train\" : group_train,\n",
    "    \"nat_train\" : nat_train,\n",
    "    \"sex_train\" : sex_train})\n",
    "sf_test = pd.DataFrame(data={\n",
    "    \"group_test\" : group_test,\n",
    "    \"nat_test\" : nat_test,\n",
    "    \"sex_test\" : sex_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fairML model accuracy for Logistic Regression is: 0.76146982735864\n"
     ]
    }
   ],
   "source": [
    "# implementing fairlearn model optimizer\n",
    "fair_model = LogisticRegression()\n",
    "unmitigated_lr = fair_model.fit(X_train, y_train)\n",
    "\n",
    "# define the constraint - example: demographic parity\n",
    "# define the objective - example: balanced accuracy score\n",
    "postprocess_est = ThresholdOptimizer(\n",
    "                   estimator=unmitigated_lr,\n",
    "                   constraints=\"demographic_parity\",\n",
    "                   objective=\"balanced_accuracy_score\",\n",
    "                   prefit=True,\n",
    "                   predict_method='predict_proba') \n",
    "\n",
    "postprocess_est.fit(X_train, y_train, sensitive_features=sf_train)\n",
    "\n",
    "yhat = postprocess_est.predict(X_test, sensitive_features=sf_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print(\"The fairML model accuracy for Logistic Regression is:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 36 subgroups. Evaluation may be slow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Demographic Parity Difference is: 0.7096774193548387\n"
     ]
    }
   ],
   "source": [
    "# check demographic parity post fairML model\n",
    "diff_fair_dem = demographic_parity_difference(y_test, yhat, sensitive_features=sf_test)\n",
    "print(\"The Demographic Parity Difference is:\", diff_fair_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Demographic Parity Ratio is: 0.4166666666666667\n"
     ]
    }
   ],
   "source": [
    "# check demographic parity post fairML model\n",
    "ratio_fair_dem = demographic_parity_ratio(y_test, yhat, sensitive_features=group_test)\n",
    "print(\"The Demographic Parity Ratio is:\", ratio_fair_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>sel</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>White alone</th>\n",
       "      <td>0.772213</td>\n",
       "      <td>0.862131</td>\n",
       "      <td>0.302716</td>\n",
       "      <td>0.55699</td>\n",
       "      <td>46245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black or African American alone</th>\n",
       "      <td>0.748036</td>\n",
       "      <td>0.88131</td>\n",
       "      <td>0.339775</td>\n",
       "      <td>0.554863</td>\n",
       "      <td>3691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Indian alone</th>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.341108</td>\n",
       "      <td>0.53902</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Indian alone</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Indian/Alaska Native specified/not specified or no other races</th>\n",
       "      <td>0.69375</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.6</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian alone</th>\n",
       "      <td>0.758833</td>\n",
       "      <td>0.824034</td>\n",
       "      <td>0.305792</td>\n",
       "      <td>0.563763</td>\n",
       "      <td>12170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Native Hawaiian and Other Pacific Islander alone</th>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.358779</td>\n",
       "      <td>0.547414</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Some Other Race alone</th>\n",
       "      <td>0.765955</td>\n",
       "      <td>0.863747</td>\n",
       "      <td>0.317139</td>\n",
       "      <td>0.568235</td>\n",
       "      <td>8947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two or More Races</th>\n",
       "      <td>0.792242</td>\n",
       "      <td>0.983382</td>\n",
       "      <td>0.318908</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>3764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    accuracy       tpr  \\\n",
       "Race                                                                     \n",
       "White alone                                         0.772213  0.862131   \n",
       "Black or African American alone                     0.748036   0.88131   \n",
       "American Indian alone                               0.736842  0.865385   \n",
       "American Indian alone                                    0.5       0.5   \n",
       "American Indian/Alaska Native specified/not spe...   0.69375  0.797468   \n",
       "Asian alone                                         0.758833  0.824034   \n",
       "Native Hawaiian and Other Pacific Islander alone    0.706897  0.792079   \n",
       "Some Other Race alone                               0.765955  0.863747   \n",
       "Two or More Races                                   0.792242  0.983382   \n",
       "\n",
       "                                                         fpr       sel  count  \n",
       "Race                                                                           \n",
       "White alone                                         0.302716   0.55699  46245  \n",
       "Black or African American alone                     0.339775  0.554863   3691  \n",
       "American Indian alone                               0.341108   0.53902    551  \n",
       "American Indian alone                                    0.5       0.5      4  \n",
       "American Indian/Alaska Native specified/not spe...  0.407407       0.6    160  \n",
       "Asian alone                                         0.305792  0.563763  12170  \n",
       "Native Hawaiian and Other Pacific Islander alone    0.358779  0.547414    232  \n",
       "Some Other Race alone                               0.317139  0.568235   8947  \n",
       "Two or More Races                                   0.318908  0.563231   3764  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a MetricFrame\n",
    "mf_threshold = MetricFrame(\n",
    "    metrics=my_metrics,\n",
    "    y_true=y_test,\n",
    "    y_pred=yhat,\n",
    "    sensitive_features={\"Race\":group_test}\n",
    ")\n",
    "\n",
    "linear_fairML_results_dem = mf_threshold.by_group.rename(index=race)\n",
    "linear_fairML_results_dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 36 subgroups. Evaluation may be slow\n"
     ]
    }
   ],
   "source": [
    "mf_threshold = MetricFrame(\n",
    "    metrics=my_metrics,\n",
    "    y_true=y_test,\n",
    "    y_pred=yhat,\n",
    "    sensitive_features=sf_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>sel</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_test</th>\n",
       "      <th>nat_test</th>\n",
       "      <th>sex_test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.797826</td>\n",
       "      <td>0.852981</td>\n",
       "      <td>0.249033</td>\n",
       "      <td>0.526448</td>\n",
       "      <td>19132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.766601</td>\n",
       "      <td>0.856505</td>\n",
       "      <td>0.295523</td>\n",
       "      <td>0.524758</td>\n",
       "      <td>19186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.703334</td>\n",
       "      <td>0.678516</td>\n",
       "      <td>0.245797</td>\n",
       "      <td>0.536624</td>\n",
       "      <td>3809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.683827</td>\n",
       "      <td>0.751092</td>\n",
       "      <td>0.370079</td>\n",
       "      <td>0.539582</td>\n",
       "      <td>4118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.732703</td>\n",
       "      <td>0.884488</td>\n",
       "      <td>0.352074</td>\n",
       "      <td>0.542874</td>\n",
       "      <td>1691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.759627</td>\n",
       "      <td>0.849635</td>\n",
       "      <td>0.300292</td>\n",
       "      <td>0.519837</td>\n",
       "      <td>1714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.578571</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.684932</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.335366</td>\n",
       "      <td>0.55814</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.371069</td>\n",
       "      <td>0.528226</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.83871</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.625</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.676923</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.822185</td>\n",
       "      <td>0.975815</td>\n",
       "      <td>0.281361</td>\n",
       "      <td>0.560965</td>\n",
       "      <td>2362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.806979</td>\n",
       "      <td>0.94378</td>\n",
       "      <td>0.273109</td>\n",
       "      <td>0.52076</td>\n",
       "      <td>2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.740387</td>\n",
       "      <td>0.707057</td>\n",
       "      <td>0.204598</td>\n",
       "      <td>0.517491</td>\n",
       "      <td>3459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.693023</td>\n",
       "      <td>0.725555</td>\n",
       "      <td>0.341972</td>\n",
       "      <td>0.540759</td>\n",
       "      <td>4085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">7</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.26087</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">8</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.822065</td>\n",
       "      <td>0.952336</td>\n",
       "      <td>0.261108</td>\n",
       "      <td>0.530461</td>\n",
       "      <td>2692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.782543</td>\n",
       "      <td>0.960486</td>\n",
       "      <td>0.324029</td>\n",
       "      <td>0.562429</td>\n",
       "      <td>2635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.709915</td>\n",
       "      <td>0.674718</td>\n",
       "      <td>0.206501</td>\n",
       "      <td>0.535977</td>\n",
       "      <td>1765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.617251</td>\n",
       "      <td>0.675481</td>\n",
       "      <td>0.430108</td>\n",
       "      <td>0.540162</td>\n",
       "      <td>1855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">9</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.805623</td>\n",
       "      <td>0.989051</td>\n",
       "      <td>0.286765</td>\n",
       "      <td>0.522005</td>\n",
       "      <td>1636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.794171</td>\n",
       "      <td>0.980496</td>\n",
       "      <td>0.302862</td>\n",
       "      <td>0.534912</td>\n",
       "      <td>1647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.700441</td>\n",
       "      <td>0.699301</td>\n",
       "      <td>0.297619</td>\n",
       "      <td>0.550661</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.720472</td>\n",
       "      <td>0.79845</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.582677</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              accuracy       tpr       fpr       sel  count\n",
       "group_test nat_test sex_test                                               \n",
       "1          1        1         0.797826  0.852981  0.249033  0.526448  19132\n",
       "                    2         0.766601  0.856505  0.295523  0.524758  19186\n",
       "           2        1         0.703334  0.678516  0.245797  0.536624   3809\n",
       "                    2         0.683827  0.751092  0.370079  0.539582   4118\n",
       "2          1        1         0.732703  0.884488  0.352074  0.542874   1691\n",
       "                    2         0.759627  0.849635  0.300292  0.519837   1714\n",
       "           2        1         0.757143  0.758242  0.244898  0.578571    140\n",
       "                    2         0.684932  0.619048  0.225806  0.452055    146\n",
       "3          1        1         0.767442  0.946809  0.335366   0.55814    258\n",
       "                    2         0.693548  0.808989  0.371069  0.528226    248\n",
       "           2        1              0.8  0.666667         0       0.4     15\n",
       "                    2         0.633333     0.625  0.357143       0.5     30\n",
       "4          1        1              NaN       NaN       NaN       NaN    NaN\n",
       "                    2         0.333333         0       0.5  0.333333      3\n",
       "           2        1                0         0         0         0      1\n",
       "                    2              NaN       NaN       NaN       NaN    NaN\n",
       "5          1        1         0.703125   0.83871  0.424242     0.625     64\n",
       "                    2         0.676923  0.851852  0.447368  0.615385     65\n",
       "           2        1         0.764706      0.75       0.2  0.588235     17\n",
       "                    2         0.357143  0.333333       0.6  0.428571     14\n",
       "6          1        1         0.822185  0.975815  0.281361  0.560965   2362\n",
       "                    2         0.806979   0.94378  0.273109   0.52076   2264\n",
       "           2        1         0.740387  0.707057  0.204598  0.517491   3459\n",
       "                    2         0.693023  0.725555  0.341972  0.540759   4085\n",
       "7          1        1         0.690476  0.787879  0.372549  0.535714     84\n",
       "                    2         0.710526       0.8  0.347826  0.526316     76\n",
       "           2        1         0.806452       0.9  0.363636  0.709677     31\n",
       "                    2         0.731707  0.722222   0.26087  0.463415     41\n",
       "8          1        1         0.822065  0.952336  0.261108  0.530461   2692\n",
       "                    2         0.782543  0.960486  0.324029  0.562429   2635\n",
       "           2        1         0.709915  0.674718  0.206501  0.535977   1765\n",
       "                    2         0.617251  0.675481  0.430108  0.540162   1855\n",
       "9          1        1         0.805623  0.989051  0.286765  0.522005   1636\n",
       "                    2         0.794171  0.980496  0.302862  0.534912   1647\n",
       "           2        1         0.700441  0.699301  0.297619  0.550661    227\n",
       "                    2         0.720472   0.79845      0.36  0.582677    254"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_threshold.by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fairML model accuracy for Logistic Regression is: 0.7395596853386833\n"
     ]
    }
   ],
   "source": [
    "# implementing fairlearn model optimizer\n",
    "fair_model = LogisticRegression()\n",
    "unmitigated_lr = fair_model.fit(X_train, y_train)\n",
    "\n",
    "# define the constraint - example: demographic parity\n",
    "# define the objective - example: balanced accuracy score\n",
    "postprocess_est = ThresholdOptimizer(\n",
    "                   estimator=unmitigated_lr,\n",
    "                   constraints=\"equalized_odds\",\n",
    "                   objective=\"balanced_accuracy_score\",\n",
    "                   prefit=True,\n",
    "                   predict_method='predict_proba') \n",
    "\n",
    "postprocess_est.fit(X_train, y_train, sensitive_features=group_train)\n",
    "\n",
    "yhat = postprocess_est.predict(X_test, sensitive_features=group_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print(\"The fairML model accuracy for Logistic Regression is:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Equalized Odds Difference is: 0.09999999999999998\n"
     ]
    }
   ],
   "source": [
    "# check equalized odds parity post fairML model\n",
    "diff_fair_EO = equalized_odds_difference(y_test, yhat, sensitive_features=group_test)\n",
    "print(\"The Equalized Odds Difference is:\", diff_fair_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Equalized Odds Ratio is: 0.381123595505618\n"
     ]
    }
   ],
   "source": [
    "# check equalized odds post fairML model\n",
    "ratio_fair_EO = equalized_odds_ratio(y_test, yhat, sensitive_features=group_test)\n",
    "print(\"The Equalized Odds Ratio is:\", ratio_fair_EO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>sel</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>White alone</th>\n",
       "      <td>0.741399</td>\n",
       "      <td>0.907326</td>\n",
       "      <td>0.396868</td>\n",
       "      <td>0.62889</td>\n",
       "      <td>46245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black or African American alone</th>\n",
       "      <td>0.735844</td>\n",
       "      <td>0.91337</td>\n",
       "      <td>0.381124</td>\n",
       "      <td>0.592522</td>\n",
       "      <td>3691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Indian alone</th>\n",
       "      <td>0.704174</td>\n",
       "      <td>0.899038</td>\n",
       "      <td>0.413994</td>\n",
       "      <td>0.597096</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Indian alone</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Indian/Alaska Native specified/not specified or no other races</th>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.66875</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian alone</th>\n",
       "      <td>0.755382</td>\n",
       "      <td>0.907395</td>\n",
       "      <td>0.395288</td>\n",
       "      <td>0.650205</td>\n",
       "      <td>12170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Native Hawaiian and Other Pacific Islander alone</th>\n",
       "      <td>0.711207</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.419847</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Some Other Race alone</th>\n",
       "      <td>0.727059</td>\n",
       "      <td>0.901217</td>\n",
       "      <td>0.420922</td>\n",
       "      <td>0.641556</td>\n",
       "      <td>8947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two or More Races</th>\n",
       "      <td>0.70882</td>\n",
       "      <td>0.899566</td>\n",
       "      <td>0.402101</td>\n",
       "      <td>0.585016</td>\n",
       "      <td>3764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    accuracy       tpr  \\\n",
       "Race                                                                     \n",
       "White alone                                         0.741399  0.907326   \n",
       "Black or African American alone                     0.735844   0.91337   \n",
       "American Indian alone                               0.704174  0.899038   \n",
       "American Indian alone                                   0.25       0.5   \n",
       "American Indian/Alaska Native specified/not spe...    0.6875  0.860759   \n",
       "Asian alone                                         0.755382  0.907395   \n",
       "Native Hawaiian and Other Pacific Islander alone    0.711207  0.881188   \n",
       "Some Other Race alone                               0.727059  0.901217   \n",
       "Two or More Races                                    0.70882  0.899566   \n",
       "\n",
       "                                                         fpr       sel  count  \n",
       "Race                                                                           \n",
       "White alone                                         0.396868   0.62889  46245  \n",
       "Black or African American alone                     0.381124  0.592522   3691  \n",
       "American Indian alone                               0.413994  0.597096    551  \n",
       "American Indian alone                                      1      0.75      4  \n",
       "American Indian/Alaska Native specified/not spe...  0.481481   0.66875    160  \n",
       "Asian alone                                         0.395288  0.650205  12170  \n",
       "Native Hawaiian and Other Pacific Islander alone    0.419847   0.62069    232  \n",
       "Some Other Race alone                               0.420922  0.641556   8947  \n",
       "Two or More Races                                   0.402101  0.585016   3764  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a MetricFrame\n",
    "mf_threshold = MetricFrame(\n",
    "    metrics=my_metrics,\n",
    "    y_true=y_test,\n",
    "    y_pred=yhat,\n",
    "    sensitive_features={\"Race\":group_test}\n",
    ")\n",
    "\n",
    "linear_fairML_results_EO = mf_threshold.by_group.rename(index=race)\n",
    "linear_fairML_results_EO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---fairlearn library: non-linear---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Linear Model Accuracy is: 0.8011852594899952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0185629096176837"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Your favorite NON-LINEAR learning algorithm here #####\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print(\"Non-Linear Model Accuracy is:\", accuracy)\n",
    "\n",
    "white_tpr = np.mean(yhat[(y_test == 1) & (group_test == 1)])\n",
    "black_tpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "# Equality of opportunity violation: 0.0211\n",
    "white_tpr - black_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a MetricFrame\n",
    "mf = MetricFrame(\n",
    "    metrics=my_metrics,\n",
    "    y_true=y_test,\n",
    "    y_pred=yhat,\n",
    "    sensitive_features=group_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy    0.801185\n",
       "tpr         0.812943\n",
       "fpr         0.208608\n",
       "sel         0.483224\n",
       "count          75764\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall True Positive Rate, False Positive Rate, Selection Rate, Counts\n",
    "mf.overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# by group analysis\n",
    "RF_results = mf.by_group.rename(index=race)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographic Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Demographic Parity Difference is: 0.359192348565356\n"
     ]
    }
   ],
   "source": [
    "diff_RF_dem = demographic_parity_difference(y_test, yhat, sensitive_features=group_test)\n",
    "print(\"The Demographic Parity Difference is:\", diff_RF_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Demographic Parity Ratio is: 0.5210768685795254\n"
     ]
    }
   ],
   "source": [
    "ratio_RF_dem = demographic_parity_ratio(y_test, yhat, sensitive_features=group_test)\n",
    "print(\"The Demographic Parity Ratio is:\", ratio_RF_dem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result(s):**\n",
    "* A **demographic parity difference (DPD)** of 0 is what constitutes the presence of a demographic parity. For the race DPD, a result of 0.3594 means that a perfect demographic parity has not been achieved. If we take a look at the by group analysis we can see which race selection rates were used to calculate the DPD - alaskan native and 2+ more races.\n",
    "* A **demographic parity ratio (DPR)** of 1 is what constitutes the presence of a demographic parity. For the race DPR, a result of 0.5207 means that a perfect demographic parity has not been achieved. If we take a look at the by group analysis we can see which race selection rates were used to calculate the DPR - alaskan native and 2+ more races.\n",
    "\n",
    "NOTE: The alaska native alone group only contains 4 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equalized Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Equalized Odds Difference is: 0.35672268907563026\n"
     ]
    }
   ],
   "source": [
    "diff_RF_EO = equalized_odds_difference(y_test, yhat, sensitive_features=group_test)\n",
    "print(\"The Equalized Odds Difference is:\", diff_RF_EO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Equalized Odds Ratio is: 0.2865546218487395\n"
     ]
    }
   ],
   "source": [
    "ratio_RF_EO = equalized_odds_ratio(y_test, yhat, sensitive_features=group_test)\n",
    "print(\"The Equalized Odds Ratio is:\", ratio_RF_EO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result(s):**\n",
    "* A **equalized odds difference (EOD)** of 0 is what constitutes the presence of equalized odds. For the race EOD, a result of 0.3575 means that perfect equalized odds have not been achieved. If we take a look at the by group analysis we can see which race selection rates were used to calculate the EOD - alaska native and 2+ more races. \n",
    "* A **equalized odds ratio (EOR)** of 1 is what constitutes the presence of equalized odds. For the race EOR, a result of 0.2848 means that perfect equalized odds have not been achieved. If we take a look at the by group analysis we can see which race selection rates were used to calculate the EOR - alaska native and 2+ more races.\n",
    "\n",
    "NOTE: The alaska native alone group only contains 4 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersecting Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_2sf = MetricFrame(metrics=my_metrics,\n",
    "                         y_true=y_test,\n",
    "                         y_pred=yhat,\n",
    "                         sensitive_features=s_f_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>sel</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.830609</td>\n",
       "      <td>0.852044</td>\n",
       "      <td>0.190374</td>\n",
       "      <td>0.517676</td>\n",
       "      <td>22941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.772786</td>\n",
       "      <td>0.761787</td>\n",
       "      <td>0.21941</td>\n",
       "      <td>0.444516</td>\n",
       "      <td>23304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.832878</td>\n",
       "      <td>0.824964</td>\n",
       "      <td>0.162257</td>\n",
       "      <td>0.414528</td>\n",
       "      <td>1831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.782796</td>\n",
       "      <td>0.762029</td>\n",
       "      <td>0.202566</td>\n",
       "      <td>0.433871</td>\n",
       "      <td>1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>1</th>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.834951</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.432234</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.71223</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.271676</td>\n",
       "      <td>0.428058</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>1</th>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.27907</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>1</th>\n",
       "      <td>0.835595</td>\n",
       "      <td>0.876329</td>\n",
       "      <td>0.210972</td>\n",
       "      <td>0.565882</td>\n",
       "      <td>5821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.757915</td>\n",
       "      <td>0.780562</td>\n",
       "      <td>0.261779</td>\n",
       "      <td>0.503071</td>\n",
       "      <td>6349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>1</th>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.90566</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.752137</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>1</th>\n",
       "      <td>0.848328</td>\n",
       "      <td>0.883893</td>\n",
       "      <td>0.189289</td>\n",
       "      <td>0.546332</td>\n",
       "      <td>4457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.734521</td>\n",
       "      <td>0.715228</td>\n",
       "      <td>0.25234</td>\n",
       "      <td>0.439866</td>\n",
       "      <td>4490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">9</th>\n",
       "      <th>1</th>\n",
       "      <td>0.869028</td>\n",
       "      <td>0.863965</td>\n",
       "      <td>0.127986</td>\n",
       "      <td>0.400966</td>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.81536</td>\n",
       "      <td>0.76912</td>\n",
       "      <td>0.158113</td>\n",
       "      <td>0.380852</td>\n",
       "      <td>1901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy       tpr       fpr       sel  count\n",
       "Race Sex                                               \n",
       "1    1    0.830609  0.852044  0.190374  0.517676  22941\n",
       "     2    0.772786  0.761787   0.21941  0.444516  23304\n",
       "2    1    0.832878  0.824964  0.162257  0.414528   1831\n",
       "     2    0.782796  0.762029  0.202566  0.433871   1860\n",
       "3    1    0.820513  0.834951  0.188235  0.432234    273\n",
       "     2     0.71223  0.685714  0.271676  0.428058    278\n",
       "4    1           1         1         0         1      1\n",
       "     2    0.666667         1       0.5  0.666667      3\n",
       "5    1    0.839506  0.813953  0.131579  0.493827     81\n",
       "     2    0.734177      0.75   0.27907  0.493671     79\n",
       "6    1    0.835595  0.876329  0.210972  0.565882   5821\n",
       "     2    0.757915  0.780562  0.261779  0.503071   6349\n",
       "7    1    0.808696   0.90566  0.274194  0.565217    115\n",
       "     2    0.752137  0.791667  0.275362  0.487179    117\n",
       "8    1    0.848328  0.883893  0.189289  0.546332   4457\n",
       "     2    0.734521  0.715228   0.25234  0.439866   4490\n",
       "9    1    0.869028  0.863965  0.127986  0.400966   1863\n",
       "     2     0.81536   0.76912  0.158113  0.380852   1901"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_2sf.by_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reductions: ThresholdOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fairML model accuracy for Random Forest is: 0.7960112982419091\n"
     ]
    }
   ],
   "source": [
    "# implementing fairlearn model optimizer\n",
    "fair_model = RandomForestClassifier()\n",
    "unmitigated_rf = fair_model.fit(X_train, y_train)\n",
    "\n",
    "# define the constraint - example: demographic parity\n",
    "# define the objective - example: balanced accuracy score\n",
    "postprocess_est = ThresholdOptimizer(\n",
    "                   estimator=unmitigated_rf,\n",
    "                   constraints=\"demographic_parity\",\n",
    "                   objective=\"balanced_accuracy_score\",\n",
    "                   prefit=True,\n",
    "                   predict_method='predict_proba') \n",
    "\n",
    "postprocess_est.fit(X_train, y_train, sensitive_features=group_train)\n",
    "\n",
    "yhat = postprocess_est.predict(X_test, sensitive_features=group_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print(\"The fairML model accuracy for Random Forest is:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Demographic Parity Difference is: 0.5189101524489135\n"
     ]
    }
   ],
   "source": [
    "# check demographic parity post fairML model\n",
    "diff_fairRF_dem = demographic_parity_difference(y_test, yhat, sensitive_features=group_test)\n",
    "print(\"The Demographic Parity Difference is:\", diff_fairRF_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Demographic Parity Ratio is: 0.4810898475510866\n"
     ]
    }
   ],
   "source": [
    "# check demographic parity post fairML model\n",
    "ratio_fairRF_dem = demographic_parity_ratio(y_test, yhat, sensitive_features=group_test)\n",
    "print(\"The Demographic Parity Ratio is:\", ratio_fairRF_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>sel</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensitive_feature_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>White alone</th>\n",
       "      <td>0.80147</td>\n",
       "      <td>0.810514</td>\n",
       "      <td>0.206065</td>\n",
       "      <td>0.480809</td>\n",
       "      <td>46245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black or African American alone</th>\n",
       "      <td>0.80764</td>\n",
       "      <td>0.791951</td>\n",
       "      <td>0.182022</td>\n",
       "      <td>0.424275</td>\n",
       "      <td>3691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Indian alone</th>\n",
       "      <td>0.76588</td>\n",
       "      <td>0.759615</td>\n",
       "      <td>0.230321</td>\n",
       "      <td>0.430127</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Indian alone</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Indian/Alaska Native specified/not specified or no other races</th>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.78481</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>0.49375</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian alone</th>\n",
       "      <td>0.79507</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.239202</td>\n",
       "      <td>0.533114</td>\n",
       "      <td>12170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Native Hawaiian and Other Pacific Islander alone</th>\n",
       "      <td>0.780172</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.274809</td>\n",
       "      <td>0.525862</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Some Other Race alone</th>\n",
       "      <td>0.791215</td>\n",
       "      <td>0.809246</td>\n",
       "      <td>0.224106</td>\n",
       "      <td>0.492903</td>\n",
       "      <td>8947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two or More Races</th>\n",
       "      <td>0.841923</td>\n",
       "      <td>0.816474</td>\n",
       "      <td>0.143277</td>\n",
       "      <td>0.390808</td>\n",
       "      <td>3764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    accuracy       tpr  \\\n",
       "sensitive_feature_0                                                      \n",
       "White alone                                          0.80147  0.810514   \n",
       "Black or African American alone                      0.80764  0.791951   \n",
       "American Indian alone                                0.76588  0.759615   \n",
       "American Indian alone                                   0.75         1   \n",
       "American Indian/Alaska Native specified/not spe...    0.7875   0.78481   \n",
       "Asian alone                                          0.79507  0.829647   \n",
       "Native Hawaiian and Other Pacific Islander alone    0.780172  0.851485   \n",
       "Some Other Race alone                               0.791215  0.809246   \n",
       "Two or More Races                                   0.841923  0.816474   \n",
       "\n",
       "                                                         fpr       sel  count  \n",
       "sensitive_feature_0                                                            \n",
       "White alone                                         0.206065  0.480809  46245  \n",
       "Black or African American alone                     0.182022  0.424275   3691  \n",
       "American Indian alone                               0.230321  0.430127    551  \n",
       "American Indian alone                                    0.5      0.75      4  \n",
       "American Indian/Alaska Native specified/not spe...  0.209877   0.49375    160  \n",
       "Asian alone                                         0.239202  0.533114  12170  \n",
       "Native Hawaiian and Other Pacific Islander alone    0.274809  0.525862    232  \n",
       "Some Other Race alone                               0.224106  0.492903   8947  \n",
       "Two or More Races                                   0.143277  0.390808   3764  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a MetricFrame\n",
    "mf_threshold = MetricFrame(\n",
    "    metrics=my_metrics,\n",
    "    y_true=y_test,\n",
    "    y_pred=yhat,\n",
    "    sensitive_features={\"Race\":group_test}\n",
    ")\n",
    "\n",
    "RF_fairML_results_dem = mf.by_group.rename(index=race)\n",
    "RF_fairML_results_dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fairML model accuracy for Random Forest is: 0.7963412702602819\n"
     ]
    }
   ],
   "source": [
    "# implementing fairlearn model optimizer\n",
    "fair_model = RandomForestClassifier()\n",
    "unmitigated_rf = fair_model.fit(X_train, y_train)\n",
    "\n",
    "# define the constraint - example: demographic parity\n",
    "# define the objective - example: balanced accuracy score\n",
    "postprocess_est = ThresholdOptimizer(\n",
    "                   estimator=unmitigated_rf,\n",
    "                   constraints=\"demographic_parity\",\n",
    "                   objective=\"balanced_accuracy_score\",\n",
    "                   prefit=True,\n",
    "                   predict_method='predict_proba') \n",
    "\n",
    "postprocess_est.fit(X_train, y_train, sensitive_features=group_train)\n",
    "\n",
    "yhat = postprocess_est.predict(X_test, sensitive_features=group_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print(\"The fairML model accuracy for Random Forest is:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Equalized Odds Difference is: 0.7977748691099477\n"
     ]
    }
   ],
   "source": [
    "# check demographic parity post fairML model\n",
    "diff_fairRF_EO = equalized_odds_difference(y_test, yhat, sensitive_features=group_test)\n",
    "print(\"The Equalized Odds Difference is:\", diff_fairRF_EO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Equalized Odds Ratio is: 0.20222513089005237\n"
     ]
    }
   ],
   "source": [
    "# check demographic parity post fairML model\n",
    "ratio_fairRF_EO = equalized_odds_ratio(y_test, yhat, sensitive_features=group_test)\n",
    "print(\"The Equalized Odds Ratio is:\", ratio_fairRF_EO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>sel</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>White alone</th>\n",
       "      <td>0.800216</td>\n",
       "      <td>0.808088</td>\n",
       "      <td>0.206343</td>\n",
       "      <td>0.479857</td>\n",
       "      <td>46245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black or African American alone</th>\n",
       "      <td>0.791114</td>\n",
       "      <td>0.937926</td>\n",
       "      <td>0.305618</td>\n",
       "      <td>0.55676</td>\n",
       "      <td>3691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Indian alone</th>\n",
       "      <td>0.738657</td>\n",
       "      <td>0.918269</td>\n",
       "      <td>0.370262</td>\n",
       "      <td>0.577132</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Indian alone</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Indian/Alaska Native specified/not specified or no other races</th>\n",
       "      <td>0.7375</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.64375</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian alone</th>\n",
       "      <td>0.78143</td>\n",
       "      <td>0.764939</td>\n",
       "      <td>0.202225</td>\n",
       "      <td>0.482334</td>\n",
       "      <td>12170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Native Hawaiian and Other Pacific Islander alone</th>\n",
       "      <td>0.775862</td>\n",
       "      <td>0.930693</td>\n",
       "      <td>0.343511</td>\n",
       "      <td>0.599138</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Some Other Race alone</th>\n",
       "      <td>0.795574</td>\n",
       "      <td>0.827494</td>\n",
       "      <td>0.231548</td>\n",
       "      <td>0.505309</td>\n",
       "      <td>8947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two or More Races</th>\n",
       "      <td>0.816419</td>\n",
       "      <td>0.971098</td>\n",
       "      <td>0.273529</td>\n",
       "      <td>0.530021</td>\n",
       "      <td>3764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    accuracy       tpr  \\\n",
       "Race                                                                     \n",
       "White alone                                         0.800216  0.808088   \n",
       "Black or African American alone                     0.791114  0.937926   \n",
       "American Indian alone                               0.738657  0.918269   \n",
       "American Indian alone                                    0.5         1   \n",
       "American Indian/Alaska Native specified/not spe...    0.7375  0.886076   \n",
       "Asian alone                                          0.78143  0.764939   \n",
       "Native Hawaiian and Other Pacific Islander alone    0.775862  0.930693   \n",
       "Some Other Race alone                               0.795574  0.827494   \n",
       "Two or More Races                                   0.816419  0.971098   \n",
       "\n",
       "                                                         fpr       sel  count  \n",
       "Race                                                                           \n",
       "White alone                                         0.206343  0.479857  46245  \n",
       "Black or African American alone                     0.305618   0.55676   3691  \n",
       "American Indian alone                               0.370262  0.577132    551  \n",
       "American Indian alone                                      1         1      4  \n",
       "American Indian/Alaska Native specified/not spe...  0.407407   0.64375    160  \n",
       "Asian alone                                         0.202225  0.482334  12170  \n",
       "Native Hawaiian and Other Pacific Islander alone    0.343511  0.599138    232  \n",
       "Some Other Race alone                               0.231548  0.505309   8947  \n",
       "Two or More Races                                   0.273529  0.530021   3764  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a MetricFrame\n",
    "mf_threshold = MetricFrame(\n",
    "    metrics=my_metrics,\n",
    "    y_true=y_test,\n",
    "    y_pred=yhat,\n",
    "    sensitive_features={\"Race\":group_test}\n",
    ")\n",
    "\n",
    "RF_fairML_results_EO = mf_threshold.by_group.rename(index=race)\n",
    "RF_fairML_results_EO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---Visualizing Results---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Order of Results:\n",
    "##\n",
    "## 1. linear_results\n",
    "## 2. linear_fairML_results_dem\n",
    "## 3. RF_results\n",
    "## 4. RF_fairML_results_dem\n",
    "s = \"American Indian alone\"\n",
    "dem1 = linear_results.drop([s])[\"sel\"].max() - linear_results.drop([s])[\"sel\"].min()\n",
    "dem2 = linear_fairML_results_dem.drop([s])[\"sel\"].max() - linear_fairML_results_dem.drop([s])[\"sel\"].min()\n",
    "dem3 = RF_results.drop([s])[\"sel\"].max() - RF_results.drop([s])[\"sel\"].min()\n",
    "dem4 = RF_fairML_results_dem.drop([s])[\"sel\"].max() - RF_fairML_results_dem.drop([s])[\"sel\"].min()\n",
    "\n",
    "EO1 = linear_results.drop([s])[\"sel\"].max() - linear_results.drop([s])[\"sel\"].min()\n",
    "EO2 = linear_fairML_results_EO.drop([s])[\"sel\"].max() - linear_fairML_results_EO.drop([s])[\"sel\"].min()\n",
    "EO3 = RF_results.drop([s])[\"sel\"].max() - RF_results.drop([s])[\"sel\"].min()\n",
    "EO4 = RF_fairML_results_EO.drop([s])[\"sel\"].max() - RF_fairML_results_EO.drop([s])[\"sel\"].min()\n",
    "\n",
    "dem_diffs = {\n",
    "    \"Linear\"       : dem1,\n",
    "    \"LinearFairML\" : dem2,\n",
    "    \"RF\"           : dem3,\n",
    "    \"RFFairML\"     : dem4\n",
    "}\n",
    "\n",
    "EO_diffs = {\n",
    "    \"Linear\"       : EO1,\n",
    "    \"LinearFairML\" : EO2,\n",
    "    \"RF\"           : EO3,\n",
    "    \"RFFairML\"     : EO4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (10, 5))\n",
    " \n",
    "\n",
    "# creating the bar plot\n",
    "plt.bar(dem_diffs.keys(), dem_diffs.values(), color ='maroon',\n",
    "        width = 0.4)\n",
    " \n",
    "plt.xlabel(\"Model Type\")\n",
    "plt.ylabel(\"Demographic Parity Differences\")\n",
    "plt.title(\"Comparing Demographic Parities Across Models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (10, 5))\n",
    " \n",
    "\n",
    "# creating the bar plot\n",
    "plt.bar(EO_diffs.keys(), EO_diffs.values(), color ='maroon',\n",
    "        width = 0.4)\n",
    " \n",
    "plt.xlabel(\"Model Type\")\n",
    "plt.ylabel(\"Equalized Odds Differences\")\n",
    "plt.title(\"Comparing Equalized Odds Across Models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing the target variable to a continuous value and exploring fairness within regression:\n",
    "The progress of this section has been moved to a separate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from fairlearn.reductions import GridSearch\n",
    "from fairlearn.reductions import DemographicParity, ErrorRate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from fairlearn.reductions import ExponentiatedGradient\n",
    "from fairlearn.reductions import BoundedGroupLoss, ZeroOneLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null values: there are 63086 NaN values\n",
    "cont_labels = acs_data[\"WAGP\"]\n",
    "\n",
    "t = pd.DataFrame(np.hstack((features, np.array(cont_labels).reshape(-1, 1)))).dropna()\n",
    "cont_features, cont_labels, cont_group = t.iloc[:, 0:16], t.iloc[:,16], t[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standerdize the data\n",
    "scaler = MinMaxScaler().fit(cont_features)\n",
    "scaler_cont = MinMaxScaler().fit(np.array(cont_labels).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test sets\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    cont_features, cont_labels, cont_group, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = scaler_cont.transform(np.array(y_train).reshape(-1, 1))\n",
    "y_test = scaler_cont.transform(np.array(y_test).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model MAE is: 0.06262536327522135\n"
     ]
    }
   ],
   "source": [
    "# train a simple liner regressor and evaluate\n",
    "linear = LinearRegression()\n",
    "linear.fit(X_train, y_train)\n",
    "\n",
    "yhat = linear.predict(X_test)\n",
    "linear_MAE = mean_absolute_error(y_test, yhat)\n",
    "print(\"Linear Model MAE is:\", linear_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-406-1212f19eaa3e>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Model MAE is: 0.052219985706353896\n"
     ]
    }
   ],
   "source": [
    "# train a Random Forest regressor\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "yhat = rf.predict(X_test)\n",
    "rf_MAE = mean_absolute_error(y_test, yhat)\n",
    "print(\"RF Model MAE is:\", rf_MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fairness in-processing: ExponentiatedGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ExponentiatedGradient\n",
    "sweep = GridSearch(LinearRegression(),\n",
    "                  constraints=BoundedGroupLoss(ZeroOneLoss(), upper_bound=0.1),\n",
    "                  grid_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The grid has 8 dimensions. It is not recommended to use more than 4, otherwise a prohibitively large grid size is required to explore the space thoroughly. For such cases consider using ExponentiatedGradient from the fairlearn.reductions module.\n",
      "Generating a grid with 4 grid points. It is recommended to use at least 256 grid points. Please consider increasing grid_size.\n"
     ]
    }
   ],
   "source": [
    "# fit the in-processor\n",
    "sweep.fit(X_train, y_train,\n",
    "          sensitive_features=group_train.rename(\"race\"))\n",
    "\n",
    "predictors = sweep.predictors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairML_errors, fairML_disparities, t1 = [], [], []\n",
    "for m in predictors:\n",
    "    def classifier(X): return m.predict(X)\n",
    "    \n",
    "    m.fit(X_train, y_train)\n",
    "\n",
    "    yhat = m.predict(X_test)\n",
    "    m_MAE = mean_absolute_error(y_test, yhat)\n",
    "    fairML_errors.append(m_MAE)\n",
    "    \n",
    "    # evaluate disparities\n",
    "    #mae_frame = MetricFrame(metrics=mean_absolute_error,\n",
    "    #                    y_true=y_test,\n",
    "    #                    y_pred=yhat,\n",
    "    #                    sensitive_features=group_test.rename(\"race\"))\n",
    "    \n",
    "    bgl = BoundedGroupLoss(ZeroOneLoss(), upper_bound=0.1)\n",
    "    bgl.load_data(X_test, y_test, sensitive_features=group_test.rename(\"race\"))\n",
    "    fairML_disparities.append(bgl.gamma(lambda X: yhat))\n",
    "    \n",
    "    # ---\n",
    "    #bgl = BoundedGroupLoss(ZeroOneLoss(), upper_bound=0.1)\n",
    "    #bgl.load_data(X_test, y_test, sensitive_features=group_test.rename(\"race\"))\n",
    "    #t1.append(bgl.gamma(lambda X: yhat))\n",
    "    \n",
    "    #error = ErrorRate()\n",
    "    #error.load_data(X_train, pd.Series(Y_train), sensitive_features=A_train)\n",
    "    #disparity = DemographicParity()\n",
    "    #disparity.load_data(X_train, pd.Series(Y_train), sensitive_features=A_train)\n",
    "\n",
    "    #errors.append(error.gamma(classifier)[0])\n",
    "    #disparities.append(disparity.gamma(classifier).max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
